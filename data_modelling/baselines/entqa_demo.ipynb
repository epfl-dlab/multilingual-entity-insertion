{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualEncoder(nn.Module):\n",
    "    def __init__(self, mention_encoder,\n",
    "                 entity_encoder,\n",
    "                 type_loss):\n",
    "        super(DualEncoder, self).__init__()\n",
    "        self.mention_encoder = mention_encoder\n",
    "        self.entity_encoder = entity_encoder\n",
    "\n",
    "    def encode(self, mention_token_ids=None,\n",
    "               mention_masks=None,\n",
    "               candidate_token_ids=None,\n",
    "               candidate_masks=None,\n",
    "               entity_token_ids=None,\n",
    "               entity_masks=None):\n",
    "        candidates_embeds = None\n",
    "        mention_embeds = None\n",
    "        entity_embeds = None\n",
    "        # candidate_token_ids and mention_token_ids not None during training\n",
    "        # mention_token_ids not None for embedding mentions during inference\n",
    "        # entity_token_ids not None for embedding entities during inference\n",
    "        if candidate_token_ids is not None:\n",
    "            B, C, L = candidate_token_ids.size()\n",
    "            candidate_token_ids = candidate_token_ids.view(-1, L)\n",
    "            candidate_masks = candidate_masks.view(-1, L)\n",
    "            # B X C X L --> BC X L\n",
    "            candidates_embeds = self.entity_encoder(\n",
    "                input_ids=candidate_token_ids,\n",
    "                attention_mask=candidate_masks\n",
    "            )[0][:, 0, :].view(B, C, -1)\n",
    "        if mention_token_ids is not None:\n",
    "            mention_embeds = self.mention_encoder(\n",
    "                input_ids=mention_token_ids,\n",
    "                attention_mask=mention_masks\n",
    "            )[0][:, 0, :]\n",
    "        if entity_token_ids is not None:\n",
    "            # for getting all the entity embeddings\n",
    "            entity_embeds = self.entity_encoder(input_ids=entity_token_ids,\n",
    "                                                attention_mask=entity_masks)[\n",
    "                                0][:, 0, :]\n",
    "        return mention_embeds, candidates_embeds, entity_embeds\n",
    "\n",
    "    def forward(self,\n",
    "                mention_token_ids=None,\n",
    "                mention_masks=None,\n",
    "                candidate_token_ids=None,\n",
    "                candidate_masks=None,\n",
    "                entity_token_ids=None,\n",
    "                entity_masks=None\n",
    "                ):\n",
    "        \"\"\"\n",
    "\n",
    "        :param inputs: [\n",
    "                        mention_token_ids,mention_masks,  size: B X L\n",
    "                        candidate_token_ids,candidate_masks, size: B X C X L\n",
    "                        passages_labels, size: B X C\n",
    "                        ]\n",
    "        :return: loss, logits\n",
    "\n",
    "        \"\"\"\n",
    "        return self.encode(mention_token_ids, mention_masks,\n",
    "                            candidate_token_ids, candidate_masks,\n",
    "                            entity_token_ids, entity_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(is_init, config_path, model_path, device, type_loss,\n",
    "               blink=True):\n",
    "    with open(config_path) as json_file:\n",
    "        params = json.load(json_file)\n",
    "    if blink:\n",
    "        ctxt_bert = BertModel.from_pretrained(params[\"bert_model\"])\n",
    "        cand_bert = BertModel.from_pretrained(params[\"bert_model\"])\n",
    "    else:\n",
    "        ctxt_bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "        cand_bert = BertModel.from_pretrained('bert-large-uncased')\n",
    "    state_dict = torch.load(model_path) if device.type == 'cuda' else \\\n",
    "        torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    if is_init:\n",
    "        if blink:\n",
    "            ctxt_dict = OrderedDict()\n",
    "            cand_dict = OrderedDict()\n",
    "            for k, v in state_dict.items():\n",
    "                if k[:26] == 'context_encoder.bert_model':\n",
    "                    new_k = k[27:]\n",
    "                    ctxt_dict[new_k] = v\n",
    "                if k[:23] == 'cand_encoder.bert_model':\n",
    "                    new_k = k[24:]\n",
    "                    cand_dict[new_k] = v\n",
    "            ctxt_bert.load_state_dict(ctxt_dict, strict=False)\n",
    "            cand_bert.load_state_dict(cand_dict, strict=False)\n",
    "        model = DualEncoder(ctxt_bert, cand_bert, type_loss)\n",
    "    else:\n",
    "        model = DualEncoder(ctxt_bert, cand_bert, type_loss)\n",
    "        model.load_state_dict(state_dict['sd'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baab02e451e43bc88eaf7b97b8501c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6add4a8940a4b62833dc5d6b75e3992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model(True, 'EntQA/models/biencoder_wiki_large.json', 'EntQA/retriever.pt', torch.device('cpu'), None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0eb032a9a514dd8af7b9868ab5c43c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0feace748b1c4772b2ebb31dc8e06188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0955b4764cb40269a89ef7103e1f549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = \"\"\"Ordinal numbers (or ordinals) are numbers that show something's order, for example: 1st, 2nd, 3rd, 4th, 5th.\n",
    "\n",
    "Suppose a person has four different T-shirts, and then lays them in front of the person, from left to right.\n",
    "\n",
    "    At the far left, there is the red T-shirt.\n",
    "    Right of that is the blue one.\n",
    "    Then there is the yellow one.\n",
    "    And finally, at the far right is an orange T-shirt.\n",
    "\n",
    "If the person then starts counting the shirts from the left, he would first see the red shirt. So the red shirt is the first T-shirt. The blue shirt is the second T-shirt. The yellow shirt is the third one, and the orange T-shirt is the fourth one.\n",
    "\n",
    "The first, second, third, and fourth in this case are ordinal numbers. They result from the fact that the person has many objects, and they give them an order (hence 'ordinal'). The person then simply counts those objects, and gives the ordinal numbers to them.\n",
    "\n",
    "In set theory, ordinals are also ordinal numbers people use to order infinite sets. An example is the set ω 0 {\\displaystyle \\omega _{0}} (or ω {\\displaystyle \\omega } for short), which is the set containing all natural numbers (including 0).[1][2] This is the smallest ordinal number that is infinite, and there are many more (such as ω {\\displaystyle \\omega } + 1).[3] \"\"\"\n",
    "passage = \"\"\"People use symbols to represent numbers; they call them numerals. Common places where numerals are used are for labeling, as in telephone numbers, for ordering, as in serial numbers, or to put a unique identifier, as in an ISBN, a unique number that can identify a book.\n",
    "    Cardinal numbers are used to measure how many items are in a set. For example, {A,B,C} has size \"3\".\n",
    "    Ordinal numbers are used to specify a certain element in a set or sequence (first, second, third).\n",
    "\n",
    "Numbers are also used for other things like counting. Numbers are used when things are measured. Numbers are used to study how the world works. Mathematics is a way to use numbers to learn about the world and make things. The study of the rules of the natural world is called science. The work that uses numbers to make things is called engineering. \"\"\"\n",
    "passage_false = \"\"\"A keloid is a type of scar that can form where somebody has an injury.[1] Keloids are tough and get larger over time, not going away. They can become as big as 30 centimeters long. They are shaped irregularly, rising high above the skin.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_tokens = tokenizer([entity], return_tensors='pt', padding=True, max_length=100, truncation=True)\n",
    "passage_tokens = tokenizer([passage], return_tensors='pt', padding=True, max_length=100, truncation=True)\n",
    "passage_false_tokens = tokenizer([passage_false], return_tensors='pt', padding=True, max_length=100, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    passage_embedding, _, entity_embedding = model.forward(mention_token_ids=passage_tokens['input_ids'],\n",
    "                mention_masks=passage_tokens['attention_mask'],\n",
    "                entity_token_ids=entity_tokens['input_ids'],\n",
    "                entity_masks=entity_tokens['attention_mask'])\n",
    "    passage_embedding_false, _, _ = model.forward(mention_token_ids=passage_false_tokens['input_ids'],\n",
    "                mention_masks=passage_false_tokens['attention_mask'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8839])\n"
     ]
    }
   ],
   "source": [
    "# print cosine similarity between passage and entity\n",
    "print(torch.cosine_similarity(passage_embedding, entity_embedding, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5848])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cosine_similarity(passage_embedding_false, entity_embedding, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.33136409916915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        passage_embedding, _, _ = model.forward(mention_token_ids=passage_tokens['input_ids'],\n",
    "                    mention_masks=passage_tokens['attention_mask'])\n",
    "end = perf_counter()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4833,  0.2775, -0.9148,  ..., -0.6494, -0.1603,  0.6491]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki_dump",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
