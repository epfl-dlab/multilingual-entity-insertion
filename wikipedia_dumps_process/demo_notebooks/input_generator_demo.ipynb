{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/scratch/tsoares/wikidumps/simplewiki-NS0-20231001/processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unencode_title(title):\n",
    "    clean_title = urllib.parse.unquote(title).replace('_', ' ')\n",
    "    return clean_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_files = glob(os.path.join(root, \"good_links*\"))\n",
    "page_files = glob(os.path.join(root, \"good_pages*\"))\n",
    "link_files.sort()\n",
    "page_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(link_files)\n",
    "print(page_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in link_files:\n",
    "    dfs.append(pd.read_parquet(file))\n",
    "df_links = pd.concat(dfs)\n",
    "df_links = df_links.sample(100_000).reset_index(drop=True)\n",
    "df_links['source_title'] = df_links['source_title'].apply(unencode_title)\n",
    "df_links['target_title'] = df_links['target_title'].apply(unencode_title)\n",
    "df_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in page_files:\n",
    "    dfs.append(pd.read_parquet(file, columns=['title', 'lead_paragraph']))\n",
    "df_pages = pd.concat(dfs)\n",
    "df_pages['title'] = df_pages['title'].apply(unencode_title)\n",
    "df_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links = df_links.to_dict(orient='records')\n",
    "df_pages = df_pages.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_map = pd.read_parquet(os.path.join(root, \"mention_map.parquet\"))\n",
    "mention_map = mention_map.to_dict(orient='records')\n",
    "entity_map = {}\n",
    "for row in mention_map:\n",
    "    title = unencode_title(row['target_title'])\n",
    "    mention = row['mention']    \n",
    "    if title in entity_map:\n",
    "        entity_map[title].add(mention)\n",
    "    else:\n",
    "        entity_map[title] = set([mention])\n",
    "entity_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create auxiliary data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_to_all_targets = {}\n",
    "target_to_all_sources = {}\n",
    "for link in tqdm(df_links):\n",
    "    source = link['source_title']\n",
    "    target = link['target_title']\n",
    "    source_section = link['source_section'].split('<sep>')[0]\n",
    "    if source not in source_to_all_targets:\n",
    "        source_to_all_targets[source] = []\n",
    "    source_to_all_targets[source].append(target)\n",
    "    if target not in target_to_all_sources:\n",
    "        target_to_all_sources[target] = []\n",
    "    target_to_all_sources[target].append(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_leads = {}\n",
    "for page in tqdm(df_pages):\n",
    "    title = page['title']\n",
    "    lead = page['lead_paragraph']\n",
    "    page_leads[title] = lead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = []\n",
    "for row in tqdm(df_links):\n",
    "    sample = {}\n",
    "    sample['source_title'] = row['source_title']\n",
    "    sample['source_lead'] = page_leads[sample['source_title']]\n",
    "    sample['target_title'] = row['target_title']\n",
    "    sample['target_lead'] = page_leads[sample['target_title']]\n",
    "    sample['link_context'] = row['context']\n",
    "    sample['source_section'] = row['source_section'].split('<sep>')[0]\n",
    "    sample['label'] = 1\n",
    "\n",
    "    positive_samples.append(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up negative samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_strategies = {\n",
    "    'easy_replace_source': True,\n",
    "    'easy_replace_target': True,\n",
    "    'hard_replace_source': True,\n",
    "    'hard_replace_target': True,\n",
    "    'replace_context': True\n",
    "}\n",
    "negative_samples_per_positive = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build negative samples from positive ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [key for key in negative_strategies if negative_strategies[key]]\n",
    "strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = []\n",
    "for i in tqdm(range(len(positive_samples))):\n",
    "    valid_strategies = strategies.copy()\n",
    "    if len(source_to_all_targets[positive_samples[i]['source_title']]) == 1:\n",
    "        valid_strategies.remove('hard_replace_target')\n",
    "    if len(target_to_all_sources[positive_samples[i]['target_title']]) == 1:\n",
    "        valid_strategies.remove('hard_replace_source')\n",
    "    list_strategies = random.choices(valid_strategies, k=negative_samples_per_positive)\n",
    "    new_samples = []\n",
    "    for strategy in list_strategies:\n",
    "        if strategy == 'easy_replace_source':\n",
    "            new_source = random.choices(positive_samples, k=1)[0]['source_title']\n",
    "            while new_source in target_to_all_sources[positive_samples[i]['target_title']]:\n",
    "                new_source = random.choices(positive_samples, k=1)[0]['source_title']\n",
    "            new_sample = positive_samples[i].copy()\n",
    "            new_sample['source_title'] = new_source\n",
    "            new_sample['source_lead'] = page_leads[new_source]\n",
    "            new_sample['neg_type'] = 'easy_replace_source'\n",
    "        elif strategy == 'easy_replace_target':\n",
    "            new_target = random.choices(positive_samples, k=1)[0]['target_title']\n",
    "            while new_target in source_to_all_targets[positive_samples[i]['source_title']]:\n",
    "                new_target = random.choices(positive_samples, k=1)[0]['target_title']\n",
    "            new_sample = positive_samples[i].copy()\n",
    "            new_sample['target_title'] = new_target\n",
    "            new_sample['target_lead'] = page_leads[new_target]\n",
    "            new_sample['neg_type'] = 'easy_replace_target'\n",
    "        elif strategy == 'hard_replace_source':\n",
    "            new_source_section = random.choices(target_to_all_sources[positive_samples[i]['target_title']], k=1)[0]\n",
    "            new_sample = positive_samples[i].copy()\n",
    "            new_sample['source_title'] = new_source_section\n",
    "            new_sample['source_lead'] = page_leads[new_source_section]\n",
    "            new_sample['neg_type'] = 'hard_replace_source'\n",
    "        elif strategy == 'hard_replace_target':\n",
    "            safe_targets = []\n",
    "            for target in source_to_all_targets[positive_samples[i]['source_title']]:\n",
    "                found = False\n",
    "                for mention in entity_map[target]:\n",
    "                    if mention in positive_samples[i]['link_context']:\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    safe_targets.append(target)\n",
    "            if len(safe_targets) == 0:\n",
    "                new_target = random.choices(positive_samples, k=1)[0]['target_title']\n",
    "                while new_target in source_to_all_targets[positive_samples[i]['source_title']]:\n",
    "                    new_target = new_target = random.choices(positive_samples, k=1)[0]['target_title']\n",
    "            else:\n",
    "                new_target = random.choices(safe_targets, k=1)[0]\n",
    "            new_sample = positive_samples[i].copy()\n",
    "            new_sample['target_title'] = new_target\n",
    "            new_sample['target_lead'] = page_leads[new_target]\n",
    "            new_sample['neg_type'] = 'hard_replace_target'\n",
    "        elif strategy == 'replace_context':\n",
    "            new_sample = positive_samples[i].copy()\n",
    "            new_context = random.choices(positive_samples, k=1)[0]['link_context']\n",
    "            mention_words = []\n",
    "            for mention in entity_map[new_sample['target_title']]:\n",
    "                mention_words.append(mention)\n",
    "            while True:\n",
    "                found = False\n",
    "                for mention in entity_map[new_sample['target_title']]:\n",
    "                    if mention in new_context:\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    break\n",
    "                new_context = random.choices(positive_samples, k=1)[0]['link_context']\n",
    "            new_sample['link_context'] = new_context\n",
    "            new_sample['neg_type'] = 'replace_context'\n",
    "        new_sample['label'] = 0\n",
    "        new_samples.append(new_sample)\n",
    "    negative_samples.extend(new_samples)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(positive_samples + negative_samples)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.8)\n",
    "val_df = df.drop(train_df.index).sample(frac=0.5)\n",
    "test_df = df.drop(train_df.index).drop(val_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in df_pages:\n",
    "    if page['title'] == '1934':\n",
    "        print(page['lead_paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in df_links:\n",
    "    if link['source_title'] == '1934' or link['target_title'] == '1934':\n",
    "        print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mention in mention_map:\n",
    "    if '1934' == mention['mention'] or '1934' == mention['target_title']:\n",
    "        print(mention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki_dump",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
